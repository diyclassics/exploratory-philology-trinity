{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from cltkreaders.lat import LatinTesseraeCorpusReader\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deforming Catullus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus reader and select 'Catullus' files\n",
    "\n",
    "T = LatinTesseraeCorpusReader()\n",
    "catullus = [file for file in T.fileids() if 'catullus' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show text as it appears in file\n",
    "\n",
    "print(T.raw(catullus)[:490])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split raw text into individual poems\n",
    "\n",
    "poems = T.raw(catullus).strip().split('\\n\\n')\n",
    "pprint(poems[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index of poem numbers using regular expressions\n",
    "\n",
    "import re\n",
    "poem_nos = [re.match(r'<cat\\. (\\d+\\w?)\\.\\d+>', poem).group(1) for poem in poems]\n",
    "print(poem_nos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading backwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at poem 85\n",
    "\n",
    "poem_85 = poems[85]\n",
    "print(poem_85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at poem 85 with pprint\n",
    "\n",
    "pprint(poem_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split poem into lines\n",
    "\n",
    "lines_85 = []\n",
    "\n",
    "lines = poem_85.split('\\n')\n",
    "\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split lines into citation and text; keep only text\n",
    "\n",
    "text_lines = [line.split('\\t')[1] for line in lines]\n",
    "print(text_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the lines of a poem\n",
    "\n",
    "reversed_text_lines = reversed(text_lines)\n",
    "reversed_text = '\\n'.join(reversed_text_lines)\n",
    "print(reversed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise some editorial discretion...\n",
    "\n",
    "reversed_text_edition = reversed_text[0].upper() + reversed_text[1:].replace('odi', 'Odi') + '?'\n",
    "print(reversed_text_edition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract poem text\n",
    "\n",
    "def get_poem_text(poem):\n",
    "    lines = poem.split('\\n')\n",
    "    text_lines = [line.split('\\t')[1] for line in lines]\n",
    "    return '\\n'.join(text_lines)\n",
    "\n",
    "poem_85_text = get_poem_text(poems[85])\n",
    "    \n",
    "print(poem_85_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all spaces from poem\n",
    "\n",
    "poem_85_spaceless = ''.join(poem_85_text.split())\n",
    "print(poem_85_spaceless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all letters from poem\n",
    "\n",
    "poem_85_letterless = ''.join([char for char in poem_85_text if not char.isalpha()])\n",
    "print(poem_85_letterless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to remove all spaces and letters (or conversely to leave only punctuation)\n",
    "\n",
    "def leave_punctuation(poem):\n",
    "    poem = ''.join(poem.split())\n",
    "    return [char for char in poem if not char.isalpha()]\n",
    "\n",
    "print(leave_punctuation(poem_85_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all of the poems to get a list of punctuation-only poems\n",
    "\n",
    "punc_poems = [\"\".join(leave_punctuation(get_poem_text(poem))) for poem in poems]\n",
    "\n",
    "# Note that this is the same as...\n",
    "\n",
    "punc_poems = [get_poem_text(poem) for poem in poems]\n",
    "punc_poems = [leave_punctuation(poem) for poem in punc_poems]\n",
    "punc_poems = [\"\".join(poem) for poem in punc_poems]\n",
    "\n",
    "print(punc_poems[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each punctuation poem with its citation to a txt file\n",
    "\n",
    "with open('output/catullus_punc_poems.txt', 'w') as f:\n",
    "    for citation, poem in zip(poem_nos, punc_poems):\n",
    "        f.write(f'{citation}: {poem}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As above, but with sorting each punctuation poem before writing\n",
    "\n",
    "with open('output/catullus_sorted_punc_poems.txt', 'w') as f:\n",
    "    for citation, poem in zip(poem_nos, punc_poems):\n",
    "        f.write(f'{citation}: {\"\".join(sorted(poem))}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all of the punctuation poems consecutively as if one large punctuation poem\n",
    "\n",
    "punc_poems_running = []\n",
    "for poem in punc_poems:\n",
    "    punc_poems_running.append(poem)\n",
    "punc_poems_all = ''.join(punc_poems_running)\n",
    "\n",
    "with open('output/catullus_punc.txt', 'w') as f:\n",
    "    f.write(''.join(punc_poems_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all of the punctuation poems consecutively as if one large punctuation poem; alternate regex approach\n",
    "\n",
    "catullus_text = next(T.texts(catullus))\n",
    "catullus_text_no_letters = re.sub(r'[\\w\\s]', '', catullus_text)\n",
    "print(catullus_text_no_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbing Vergil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text of Aeneid 1\n",
    "\n",
    "aen_1 = 'vergil.aeneid.part.1.tess'\n",
    "print(next(T.texts(aen_1))[:315])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first pos-tagged sentence in the Aeneid\n",
    "# NB: POS-tagging is work in progress!\n",
    "\n",
    "\n",
    "virgil_pos_sents = next(T.tokenized_sents('vergil.aeneid.part.1.tess', preprocess=lambda x: x.lower()))[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sample of tagged sents\n",
    "\n",
    "print(virgil_pos_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect tagged tokens into list\n",
    "\n",
    "pos_tokens = []\n",
    "\n",
    "for sent in virgil_pos_sents:\n",
    "    for item in sent:\n",
    "        pos_tokens.append(f'{item[0]}/{item[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sample of tagged token\n",
    "\n",
    "pos_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompose lines\n",
    "\n",
    "indices = [(0, 9), (9, 16), (16, 25), (25, 33), (33, 43), (43, 51), (51, len(pos_tokens))]\n",
    "virgil_pos_lines = [pos_tokens[s:e] for s,e in indices] # cf. https://stackoverflow.com/a/18571043\n",
    "\n",
    "for line in virgil_pos_lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-verbs by looping through lines, checking pos tag, and keeping matches\n",
    "\n",
    "verb_lines = []\n",
    "\n",
    "for line in virgil_pos_lines:\n",
    "    pairs = [ ]\n",
    "    for pair in line:\n",
    "        word, pos = pair.split('/')\n",
    "        if pos == 'VERB' or pos == 'PUNCT':\n",
    "            pairs.append(word)\n",
    "        else:\n",
    "            pairs.append('     ')\n",
    "    verb_lines.append(pairs)\n",
    "\n",
    "print(verb_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make verb-only poem\n",
    "\n",
    "for line in verb_lines:\n",
    "    print(\" \".join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_lines[0][2] = 'cano'\n",
    "verb_lines[6][0] = 'inferretque'\n",
    "verb_lines[6][4] = '     '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make verb-only poem\n",
    "\n",
    "for line in verb_lines:\n",
    "    print(\" \".join(line))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('exploratory-philology')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "602b9845bb6702be41bdfdefd2bba256d92e78b624ab00c1b8e88240a331b85f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
